---
title: "4b. multinomial bayesiano"
author: "Matheus Lazzari Nicola"
format: 
  html:
    math: mathjax
    code-fold: true
    code-summary: "mostre-me o código"
    embed-resources: true
    df-print: paged 
    toc: true
    toc-depth: 2
    toc-location: left
    toc-title: sumário executivo
    grid:
      sidebar-width: 200px
      body-width: 900px  
      margin-width: 200px
      gutter-width: 1.5em
---

<style>
  p {
    text-align: justify;
  }
</style>

# pacotes

```{r}
#| warning: false
#| echo: false

pkgs<-c("tidyverse", 
        "caret",    # Para dividir os dados e avaliar os modelos    
        "brms"     # para multinomial bayesiano
        
        )

new.packages <- pkgs[!(pkgs %in% installed.packages()[,"Package"])]

if(length(new.packages)) install.packages(new.packages)

invisible(lapply(pkgs, library, character.only = TRUE))
rm(pkgs, new.packages)

conflict_prefer("filter", "dplyr")
conflict_prefer("lag", "dplyr")
conflicts_prefer(neuralnet::compute)

```

# base de dados

```{r}
load("df processo transporte.RData")
```

### validações

```{r}
# Base binária
#dados_logit$atrasou <- as.factor(dados_logit$atrasou)
#levels(dados_logit$atrasou)

# Base multinomial
#dados_mnomial$cenarios <- as.factor(dados_mnomial$cenarios)
#levels(dados_mnomial$cenarios)

# Verificar valores ausentes na base binária
#sum(is.na(dados_logit))

# Verificar valores ausentes na base multinomial
#sum(is.na(dados_mnomial))

# Verificar o balanceamento da variável resposta binária
#table(dados_logit$atrasou)
```






# processo de transporte

## (ipb) inicio do processo binomial

### treino e teste

```{r}
# Se necessário, balancear os dados de treino binário
if (min(table(df_logit_ip$atrasou)) / sum(table(df_logit_ip$atrasou)) < 0.1) {
  cat("A variável resposta está desbalanceada. Realizando balanceamento...\n")
  balanceamento <- upSample(x = df_logit_ip[, -which(names(df_logit_ip) == 'atrasou')], y = df_logit_ip$atrasou)
  df_logit_ip_balanceado <- cbind(balanceamento, atrasou = balanceamento$Class)
  df_logit_ip_balanceado$Class <- NULL
  df_logit_ip <- df_logit_ip_balanceado
} else {
  cat("Não precisa balancear!")
}

set.seed(123)
# preditores
X_ipb <- setdiff(names(df_logit_ip), c('atrasou'))

# Função para verificar se todas as variáveis categóricas têm pelo menos dois níveis
validar_categoricas <- function(treino, variaveis_categoricas) {
  all(sapply(treino[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
}

# Lista de variáveis categóricas
variaveis_categoricas <- names(df_logit_ip)[sapply(df_logit_ip, is.factor)]

# Loop para garantir que todas as variáveis categóricas no treino tenham pelo menos dois níveis
repeat {
  # Divisão inicial
  indice_ipb <- createDataPartition(df_logit_ip$atrasou, p = 0.7, list = FALSE)
  treino_ipb <- df_logit_ip[indice_ipb, ]
  teste_ipb  <- df_logit_ip[-indice_ipb, ]
  
  # Verificar se as variáveis categóricas no treino têm pelo menos dois níveis
  if (validar_categoricas(treino_ipb, variaveis_categoricas)) {
    cat("Divisão bem-sucedida. Todas as variáveis categóricas têm pelo menos dois níveis.\n")
    break
  } else {
    cat("Repetindo a divisão devido a variáveis categóricas com apenas um nível...\n")
  }
}

```


### modelo logit

```{r}
# 1. Regressão Logística Binomial
formula_ipb <- as.formula(paste("atrasou ~", paste(X_ipb, collapse = " + ")))
modelo_ipb  <- glm(formula_ipb, data = treino_ipb, family = binomial)

# Avaliar Regressão Logística Binomial
probPred_ipb <- predict(modelo_ipb, teste_ipb, type = "response")
classPred_ipb <- ifelse(probPred_ipb > 0.5, "1", "0")
confMat_ipb <- confusionMatrix(as.factor(classPred_ipb), as.factor(teste_ipb$atrasou), dnn = c("Prediction", "Reference"))
print(confMat_ipb)


```


### modelo logit bayesiano

```{r}
# Suponha que treino_ipb e teste_ipb já existam
# Ajustando um modelo logístico bayesiano com priors default
modelo_ipb_bayes <- stan_glm(
  formula_ipb,
  data = treino_ipb,
  family = binomial(link = "logit"),
  prior = normal(0, 0.5),
  seed = 123,
  chains = 2,      # apenas 1 cadeia
  iter = 1000,      # menos iterações totais 
  warmup = 25,      # warmup mais curto
  cores = 2,
  control = list(adapt_delta = 0.99, stepsize = 0.01)
)

#summary(modelo_ipb_bayes)
#posterior_interval(modelo_ipb_bayes, prob = 0.95)

#rm(indice_ipb, treino_ipb, validar_categoricas, variaveis_categoricas, X_ipb, formula_ipb, classPred_ipb, balanceamento)
```





## (ipm) inicio do processo multinomial


### treino e teste

```{r}
# Se necessário, balancear os dados de treino binário
#if (min(table(df_mnomial_ip$cenarios)) / sum(table(df_mnomial_ip$cenarios)) < 0.1) {
#  cat("A variável resposta está desbalanceada. Realizando balanceamento...\n")
#  balanceamento <- upSample(x = df_mnomial_ip[, -which(names(df_mnomial_ip) == 'cenarios')], y = df_mnomial_ip$cenarios)
#  df_mnomial_ip_balanceado <- cbind(balanceamento, cenarios = balanceamento$Class)
#  df_mnomial_ip_balanceado$Class <- NULL
#  df_mnomial_ip <- df_mnomial_ip_balanceado
#} else {
#  cat("Não precisa balancear!")
#}

set.seed(123)
# preditores
X_ipm <- setdiff(names(df_mnomial_ip), c('cenarios'))

# Função para verificar se todas as variáveis categóricas têm pelo menos dois níveis
validar_categoricas <- function(treino, variaveis_categoricas) {
  all(sapply(treino[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
}

# Lista de variáveis categóricas
variaveis_categoricas <- names(df_mnomial_ip)[sapply(df_mnomial_ip, is.factor)]

# Loop para garantir que todas as variáveis categóricas no treino tenham pelo menos dois níveis
repeat {
  # Divisão inicial
  indice_ipm <- createDataPartition(df_mnomial_ip$cenarios, p = 0.7, list = FALSE)
  treino_ipm <- df_mnomial_ip[indice_ipm, ]
  teste_ipm  <- df_mnomial_ip[-indice_ipm, ]
  
  # Verificar se as variáveis categóricas no treino têm pelo menos dois níveis
  if (validar_categoricas(treino_ipm, variaveis_categoricas)) {
    cat("Divisão bem-sucedida. Todas as variáveis categóricas têm pelo menos dois níveis.\n")
    break
  } else {
    cat("Repetindo a divisão devido a variáveis categóricas com apenas um nível...\n")
  }
}

```


### modelo multinomial

```{r}
# 1. Regressão Logística Binomial
formula_ipm <- as.formula(paste("cenarios ~", paste(X_ipm, collapse = " + ")))
modelo_ipm  <- multinom(formula_ipm, data = treino_ipm)

# Avaliar Regressão Logística Binomial
probPred_ipm <- predict(modelo_ipm, teste_ipm)
confMat_ipm <- confusionMatrix(as.factor(probPred_ipm), as.factor(teste_ipm$cenarios), dnn = c("Prediction", "Reference"))
print(confMat_ipm)





```


### modelo mnomial bayesiano

```{r}
# Modelo multinomial bayesiano
modelo_ipb_bayes <- brm(
  formula = formula_ipm,
  data = treino_ipm,
  family = categorical(link = "logit"),
  prior = c(
  set_prior("normal(0, 0.5)", class = "b", dpar = "mu2"),
  set_prior("normal(0, 0.5)", class = "b", dpar = "mu3"),
  set_prior("normal(0, 0.5)", class = "b", dpar = "mu4")),
  seed = 123,
  chains = 2,
  iter = 1000,
  warmup = 500,
  cores = 2,
  control = list(adapt_delta = 0.99, stepsize = 0.01)
)

summary(modelo_ipm_bayes)

#rm(indice_ipm, validar_categoricas, variaveis_categoricas,
#   X_ipm, formula_ipm, probPred_ipm, classPred_ipm, balanceamento, df_mnomial_ip_balanceado)
```




## (tpb) todo do processo binomial

### treino e teste

```{r}
# Se necessário, balancear os dados de treino binário
if (min(table(df_logit_tp$atrasou)) / sum(table(df_logit_tp$atrasou)) < 0.1) {
  cat("A variável resposta está desbalanceada. Realizando balanceamento...\n")
  balanceamento <- upSample(x = df_logit_tp[, -which(names(df_logit_tp) == 'atrasou')], y = df_logit_tp$atrasou)
  df_logit_tp_balanceado <- cbind(balanceamento, atrasou = balanceamento$Class)
  df_logit_tp_balanceado$Class <- NULL
  df_logit_tp <- df_logit_tp_balanceado
} else {
  cat("Não precisa balancear!")
}

set.seed(123)
# preditores
X_tpb <- setdiff(names(df_logit_tp), c('atrasou'))

# Função para verificar se todas as variáveis categóricas têm pelo menos dois níveis
validar_categoricas <- function(treino, variaveis_categoricas) {
  all(sapply(treino[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
}

# Lista de variáveis categóricas
variaveis_categoricas <- names(df_logit_tp)[sapply(df_logit_tp, is.factor)]

# Loop para garantir que todas as variáveis categóricas no treino tenham pelo menos dois níveis
repeat {
  # Divisão inicial
  indice_tpb <- createDataPartition(df_logit_tp$atrasou, p = 0.7, list = FALSE)
  treino_tpb <- df_logit_tp[indice_tpb, ]
  teste_tpb  <- df_logit_tp[-indice_tpb, ]
  
  # Verificar se as variáveis categóricas no treino têm pelo menos dois níveis
  if (validar_categoricas(treino_tpb, variaveis_categoricas)) {
    cat("Divisão bem-sucedida. Todas as variáveis categóricas têm pelo menos dois níveis.\n")
    break
  } else {
    cat("Repetindo a divisão devido a variáveis categóricas com apenas um nível...\n")
  }
}

```


### modelo logit

```{r}
# 1. Regressão Logística Binomial
formula_tpb <- as.formula(paste("atrasou ~", paste(X_tpb, collapse = " + ")))
modelo_tpb  <- glm(formula_tpb, data = treino_tpb, family = binomial)

# Avaliar Regressão Logística Binomial
probPred_tpb <- predict(modelo_tpb, teste_tpb, type = "response")
classPred_tpb <- ifelse(probPred_tpb > 0.5, "1", "0")
confMat_tpb <- confusionMatrix(as.factor(classPred_tpb), as.factor(teste_tpb$atrasou), dnn = c("Prediction", "Reference"))
print(confMat_tpb)



```

### modelo logit bayesiano

```{r}
# Suponha que treino_ipb e teste_ipb já existam
# Ajustando um modelo logístico bayesiano com priors default
modelo_tpb_bayes <- stan_glm(
  formula_tpb,
  data = treino_tpb,
  family = binomial(link = "logit"),
  prior = normal(0, 0.5),
  seed = 123,
  chains = 2,      # apenas 1 cadeia
  iter = 1000,      # menos iterações totais 
  warmup = 25,      # warmup mais curto
  cores = 2,
  control = list(adapt_delta = 0.99, stepsize = 0.01)
)

#summary(modelo_ipb_bayes)
#posterior_interval(modelo_ipb_bayes, prob = 0.95)

rm(indice_tpb, treino_tpb, validar_categoricas, variaveis_categoricas,
   X_tpb, classPred_tpb, balanceamento, df_logit_tp_balanceado)
```



## (tpm) todo do processo multinomial



### treino e teste

```{r}
# Se necessário, balancear os dados de treino binário
if (min(table(df_mnomial_tp$cenarios)) / sum(table(df_mnomial_tp$cenarios)) < 0.1) {
  cat("A variável resposta está desbalanceada. Realizando balanceamento...\n")
  balanceamento <- upSample(x = df_mnomial_tp[, -which(names(df_mnomial_tp) == 'cenarios')], y = df_mnomial_tp$cenarios)
  df_mnomial_tp_balanceado <- cbind(balanceamento, cenarios = balanceamento$Class)
  df_mnomial_tp_balanceado$Class <- NULL
  df_mnomial_tp <- df_mnomial_tp_balanceado
} else {
  cat("Não precisa balancear!")
}

set.seed(123)
# preditores
X_tpm <- setdiff(names(df_mnomial_tp), c('cenarios'))

# Função para verificar se todas as variáveis categóricas têm pelo menos dois níveis
validar_categoricas <- function(treino, variaveis_categoricas) {
  all(sapply(treino[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
}

# Lista de variáveis categóricas
variaveis_categoricas <- names(df_mnomial_tp)[sapply(df_mnomial_tp, is.factor)]

# Loop para garantir que todas as variáveis categóricas no treino tenham pelo menos dois níveis
repeat {
  # Divisão inicial
  indice_tpm <- createDataPartition(df_mnomial_tp$cenarios, p = 0.7, list = FALSE)
  treino_tpm <- df_mnomial_tp[indice_tpm, ]
  teste_tpm  <- df_mnomial_tp[-indice_tpm, ]
  
  # Verificar se as variáveis categóricas no treino têm pelo menos dois níveis
  if (validar_categoricas(treino_tpm, variaveis_categoricas)) {
    cat("Divisão bem-sucedida. Todas as variáveis categóricas têm pelo menos dois níveis.\n")
    break
  } else {
    cat("Repetindo a divisão devido a variáveis categóricas com apenas um nível...\n")
  }
}

```

### modelo multinomial

```{r}
# 1. Regressão Logística Binomial
formula_tpm <- as.formula(paste("cenarios ~", paste(X_tpm, collapse = " + ")))
modelo_tpm  <- multinom(formula_tpm, data = treino_tpm)

# Avaliar Regressão Logística Binomial
probPred_tpm <- predict(modelo_tpm, teste_tpm)
confMat_tpm <- confusionMatrix(as.factor(probPred_tpm), as.factor(teste_tpm$cenarios), dnn = c("Prediction", "Reference"))
print(confMat_tpm)

rm(indice_tpm, validar_categoricas, variaveis_categoricas,
   X_tpm, formula_tpm, probPred_tpm, classPred_tpm, balanceamento, df_mnomial_tp_balanceado)



```


# resultados

```{r}
# Calcular AUC para o modelo binomial de início do processo
roc_ipb <- roc(teste_ipb$atrasou, probPred_ipb)
auc_ipb <- auc(roc_ipb)
# Calcular AUC para o modelo binomial de todo o processo
roc_tpb <- roc(teste_tpb$atrasou, probPred_tpb)
auc_tpb <- auc(roc_tpb)
# Calcular AUC para o modelo multinomial de início do processo
probPred_ipm <- predict(modelo_ipm, teste_ipm, type = "prob")
auc_ipm <- multiclass.roc(teste_ipm$cenarios, probPred_ipm)$auc
# Calcular AUC para o modelo multinomial de todo o processo
probPred_tpm <- predict(modelo_tpm, teste_tpm, type = "prob")
auc_tpm <- multiclass.roc(teste_tpm$cenarios, probPred_tpm)$auc


post_pred <- posterior_predict(modelo_ipb_bayes, newdata = teste_ipb)
# Isso retorna uma matriz com dimensões [N_draws x N_amostras_de_teste]
# Você pode tomar a média ao longo dos draws para cada observação:
mean_preds <- colMeans(post_pred)
# Em caso de modelo binário, mean_preds seria a probabilidade média posterior de ser classe "1".
class_preds <- ifelse(mean_preds > 0.5, "1", "0")
confMat_bayes <- confusionMatrix(as.factor(class_preds), as.factor(teste_ipb$atrasou))
acc_ipb_bayes <- confMat_bayes$overall['Accuracy']
post_pred <- posterior_predict(modelo_tpb_bayes, newdata = teste_tpb)
# Isso retorna uma matriz com dimensões [N_draws x N_amostras_de_teste]
# Você pode tomar a média ao longo dos draws para cada observação:
mean_preds <- colMeans(post_pred)
# Em caso de modelo binário, mean_preds seria a probabilidade média posterior de ser classe "1".
class_preds <- ifelse(mean_preds > 0.5, "1", "0")
confMat_bayes <- confusionMatrix(as.factor(class_preds), as.factor(teste_tpb$atrasou))
acc_tpb_bayes <- confMat_bayes$overall['Accuracy']

# Para um modelo binário em brms:
post_pred_probs <- posterior_epred(modelo_ipb_bayes, newdata = teste_ipb)
# Isso gera probabilidades esperadas posterior para cada observação.
# Normalmente, será um array [N_draws x N_amostras_de_teste].
mean_prob <- colMeans(post_pred_probs)
roc_bayes <- roc(teste_ipb$atrasou, mean_prob)
auc_ipb_bayes <- auc(roc_bayes)
# Para um modelo binário em brms:
post_pred_probs <- posterior_epred(modelo_tpb_bayes, newdata = teste_tpb)
# Isso gera probabilidades esperadas posterior para cada observação.
# Normalmente, será um array [N_draws x N_amostras_de_teste].
mean_prob <- colMeans(post_pred_probs)
roc_bayes <- roc(teste_tpb$atrasou, mean_prob)
auc_tpb_bayes <- auc(roc_bayes)




resultados <- data.frame(
  Modelo = c("Logit", "Multinomial", "Logit Bayesiano"),
  Acc.ip = c(confMat_ipb$overall['Accuracy'], confMat_ipm$overall['Accuracy'], acc_ipb_bayes),
  #BIC.ip = c(bic_ipb, bic_ipm,0),
  AUC.ip = c(auc_ipb, auc_ipm, auc_ipb_bayes),
  
  Acc.tp  = c(confMat_tpb$overall['Accuracy'], confMat_tpm$overall['Accuracy'], acc_tpb_bayes),
  #BIC.tp = c(bic_tpb, bic_tpm,0),
  AUC.tp = c(auc_tpb, auc_tpm, auc_tpb_bayes)
  )

print(resultados)
```