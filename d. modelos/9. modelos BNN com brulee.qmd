---
title: "9. modelos BNN com brulee"
author: "Matheus Lazzari Nicola"
format: 
  html:
    math: mathjax
    code-fold: true
    code-summary: "mostre-me o código"
    embed-resources: true
    df-print: paged 
    toc: true
    toc-depth: 2
    toc-location: left
    toc-title: sumário executivo
    grid:
      sidebar-width: 200px
      body-width: 900px  
      margin-width: 200px
      gutter-width: 1.5em
editor_options: 
  chunk_output_type: console
---

<style>
  p {
    text-align: justify;
  }
</style>

# pacotes

```{r}
#| warning: false
#| echo: false

# Pacotes necessários
pkgs <- c("tidyverse", "conflicted", "tidymodels", "pROC",
          "caret",    # Para dividir os dados e avaliar os modelos
          "brulee"    # Para rede neural bayesiana
         )

# Instalar pacotes que não estão instalados
new.packages <- pkgs[!(pkgs %in% installed.packages()[, "Package"])]
if (length(new.packages)) install.packages(new.packages)

# Carregar pacotes
invisible(lapply(pkgs, library, character.only = TRUE))
rm(pkgs, new.packages)

# Preferências de conflitos
conflict_prefer("filter", "dplyr")
conflict_prefer("lag", "dplyr")

```

# base de dados

```{r}
setwd("C:/Users/mathe/OneDrive/4.0 Pós-graduação/4.4b Dissertação Mestrado Profissional/d. modelos")
load("df processo transporte.RData")
```






# processo de transporte

## (ipb) inicio do processo binomial

### treino e teste

```{r}
# Se necessário, balancear os dados de treino binário
#if (min(table(df_logit_ip$atrasou)) / sum(table(df_logit_ip$atrasou)) < 0.1) {
#  cat("A variável resposta está desbalanceada. Realizando balanceamento...\n")
#  balanceamento <- upSample(x = df_logit_ip[, -which(names(df_logit_ip) == 'atrasou')], y = df_logit_ip$atrasou)
#  df_logit_ip_balanceado <- cbind(balanceamento, atrasou = balanceamento$Class)
#  df_logit_ip_balanceado$Class <- NULL
#  df_logit_ip <- df_logit_ip_balanceado
#} else {
#  cat("Não precisa balancear!")
#}


set.seed(123)
# preditores
X_ipb <- setdiff(names(df_logit_ip), c('atrasou'))

# Função para verificar se todas as variáveis categóricas têm pelo menos dois níveis
validar_categoricas <- function(treino, teste, variaveis_categoricas) {
  treino_valido <- all(sapply(treino[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
  teste_valido  <- all(sapply(teste[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
  
  return(treino_valido && teste_valido)
  
}

# Lista de variáveis categóricas
variaveis_categoricas <- names(df_logit_ip)[sapply(df_logit_ip, is.factor)]

# Loop para garantir que todas as variáveis categóricas no treino e tenham pelo menos dois níveis
repeat {
  # Divisão inicial
  indice_ipb <- createDataPartition(df_logit_ip$atrasou, p = 0.7, list = FALSE)
  treino_ipb <- df_logit_ip[indice_ipb, ]
  teste_ipb  <- df_logit_ip[-indice_ipb, ]
  
  # Verificar se as variáveis categóricas no treino têm pelo menos dois níveis
  if (validar_categoricas(treino_ipb, teste_ipb, variaveis_categoricas)) {
    cat("Divisão bem-sucedida. Todas as variáveis categóricas têm pelo menos dois níveis.\n")
    break
  } else {
    cat("Repetindo a divisão devido a variáveis categóricas com apenas um nível...\n")
  }
}


```


### modelo BNN



```{r}
# Função para normalização Min-Max
z_score_normalize <- function(data) {
  as.data.frame(lapply(data, function(x) {
    (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
  }))
}

min_max_normalize <- function(data) {
  as.data.frame(lapply(data, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))))
}

# Normalizar os dados de treino
pred_treino_ipb <- treino_ipb %>%
  mutate(across(all_of(variaveis_categoricas), ~ as.numeric(as.factor(.)))) %>%
  #select(-atrasou) %>%
  z_score_normalize()

# Adicionar a variável resposta ao conjunto de treino normalizado
pred_treino_ipb$atrasou <- treino_ipb$atrasou

# Normalizar os dados de teste
pred_teste_ipb <- teste_ipb %>%
  mutate(across(all_of(variaveis_categoricas), ~ as.numeric(as.factor(.)))) %>%
  #select(-atrasou) %>%
  z_score_normalize()

# Adicionar a variável resposta ao conjunto de teste normalizado
pred_teste_ipb$atrasou <- teste_ipb$atrasou

# Treinar o modelo com brulee usando a interface de fórmula
modelo_brulee_ipb <- brulee_mlp(
  atrasou ~ .,          # Fórmula especificando a variável resposta
  data = pred_treino_ipb,
  hidden_units = 50,
  epochs = 200,
  learn_rate = 0.001,
  verbose = TRUE
)

# Fazer previsões no conjunto de teste (classes)
#previsoes <- predict(modelo_brulee_ipb, new_data = pred_teste_ipb)

# Fazer previsões no conjunto de teste (probabilidades)
probs_previsoes_ipb <- predict(modelo_brulee_ipb, new_data = pred_teste_ipb, type = "prob")

# Extrair a probabilidade da classe positiva (assumindo que "1" é a classe positiva)
probs_classe_ipb <- probs_previsoes_ipb$.pred_1

# Converter pred_teste_ipb$atrasou para numérico
pred_teste_ipb$atrasou <- as.numeric(as.character(pred_teste_ipb$atrasou))

# Calcular a AUC
roc_obj_ipb <- roc(pred_teste_ipb$atrasou, probs_classe_ipb)
auc_bnn_ipb <- auc(roc_obj_ipb)
cat("AUC:", round(auc_bnn_ipb, 6), "\n")

# Definir o limite para a probabilidade (pode ser ajustado)
limite <- 0.5

# Criar vetor de previsões de classe
previsoes_classe_ipb <- ifelse(probs_classe_ipb > limite, 1, 0)
previsoes_classe_ipb <- factor(previsoes_classe_ipb, levels = c(0, 1))

# Converter a variável resposta para fator
pred_teste_ipb$atrasou <- factor(pred_teste_ipb$atrasou, levels = c(0, 1))

# Calcular a acurácia
acc_bnn_ipb <- mean(previsoes_classe_ipb == pred_teste_ipb$atrasou)
cat("Acurácia:", round(acc_bnn_ipb, 6), "\n")

# Calcular a matriz de confusão
matriz_confusao_ipb <- confusionMatrix(previsoes_classe_ipb, pred_teste_ipb$atrasou)
print(matriz_confusao_ipb)


# Fazer previsões no conjunto de teste (probabilidades)
#probs_previsoes <- predict(modelo_brulee_ipb, new_data = pred_teste_ipb, type = "prob")

# Extrair a probabilidade da classe positiva (assumindo que "1" é a classe positiva)
#probs_classe_positiva <- probs_previsoes$.pred_1

# Converter a variável resposta para numérico (caso não esteja)
y_teste_ipb <- as.numeric(as.character(pred_teste_ipb$atrasou))

# Calcular a curva ROC
roc_obj_ipb <- roc(y_teste_ipb, probs_classe_ipb)

# Calcular a AUC
auc_bnn_ipb <- auc(roc_obj_ipb)
cat("AUC:", round(auc_bnn_ipb, 6), "\n")


acc_bnn_ipb <- mean(as.numeric(acc_bnn_ipb))
auc_bnn_ipb <- mean(as.numeric(auc_bnn_ipb))

```



## (ipm) inicio do processo multinomial


### treino e teste

```{r}
# Se necessário, balancear os dados de treino binário
#if (min(table(df_mnomial_ip$cenarios)) / sum(table(df_mnomial_ip$cenarios)) < 0.1) {
#  cat("A variável resposta está desbalanceada. Realizando balanceamento...\n")
#  balanceamento <- upSample(x = df_mnomial_ip[, -which(names(df_mnomial_ip) == 'cenarios')], y = df_mnomial_ip$cenarios)
#  df_mnomial_ip_balanceado <- cbind(balanceamento, cenarios = balanceamento$Class)
#  df_mnomial_ip_balanceado$Class <- NULL
#  df_mnomial_ip <- df_mnomial_ip_balanceado
#} else {
#  cat("Não precisa balancear!")
#}

set.seed(123)
# preditores
X_ipm <- setdiff(names(df_mnomial_ip), c('cenarios'))

# Função para verificar se todas as variáveis categóricas têm pelo menos dois níveis
validar_categoricas <- function(treino, teste, variaveis_categoricas) {
  treino_valido <- all(sapply(treino[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
  teste_valido  <- all(sapply(teste[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
  
  return(treino_valido && teste_valido)
  
}

# Lista de variáveis categóricas
variaveis_categoricas <- names(df_mnomial_ip)[sapply(df_mnomial_ip, is.factor)]

# Loop para garantir que todas as variáveis categóricas no treino e tenham pelo menos dois níveis
repeat {
  # Divisão inicial
  indice_ipm <- createDataPartition(df_mnomial_ip$cenarios, p = 0.7, list = FALSE)
  treino_ipm <- df_mnomial_ip[indice_ipm, ]
  teste_ipm  <- df_mnomial_ip[-indice_ipm, ]
  
  # Verificar se as variáveis categóricas no treino têm pelo menos dois níveis
  if (validar_categoricas(treino_ipm, teste_ipm, variaveis_categoricas)) {
    cat("Divisão bem-sucedida. Todas as variáveis categóricas têm pelo menos dois níveis.\n")
    break
  } else {
    cat("Repetindo a divisão devido a variáveis categóricas com apenas um nível...\n")
  }
}

```


### modelo BNN

```{r}
# Função para normalização Min-Max
z_score_normalize <- function(data) {
  as.data.frame(lapply(data, function(x) {
    (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
  }))
}

min_max_normalize <- function(data) {
  as.data.frame(lapply(data, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))))
}

# Normalizar os dados de treino
pred_treino_ipm <- treino_ipm %>%
  mutate(across(all_of(variaveis_categoricas), ~ as.numeric(as.factor(.)))) %>%
  #select(-cenarios) %>%
  z_score_normalize()

# Adicionar a variável resposta ao conjunto de treino normalizado
pred_treino_ipm$cenarios <- treino_ipm$cenarios

# Normalizar os dados de teste
pred_teste_ipm <- teste_ipm %>%
  mutate(across(all_of(variaveis_categoricas), ~ as.numeric(as.factor(.)))) %>%
  #select(-cenarios) %>%
  z_score_normalize()

# Adicionar a variável resposta ao conjunto de teste normalizado
pred_teste_ipm$cenarios <- teste_ipm$cenarios

# Treinar o modelo com brulee usando a interface de fórmula
modelo_brulee_ipm <- brulee_mlp(
  cenarios ~ .,          # Fórmula especificando a variável resposta
  data = pred_treino_ipm,
  hidden_units = 50,
  epochs = 200,
  learn_rate = 0.001,
  verbose = TRUE
)

# Fazer previsões no conjunto de teste (classes)
previsoes_classe_ipm <- predict(modelo_brulee_ipm, new_data = pred_teste_ipm)

# Converter para fator com os níveis corretos
previsoes_classe_ipm <- factor(previsoes_classe_ipm$.pred_class, levels = levels(pred_teste_ipm$cenarios))

# Calcular a acurácia
acc_bnn_ipm <- mean(previsoes_classe_ipm == pred_teste_ipm$cenarios)
cat("Acurácia:", round(acc_bnn_ipm, 6), "\n")

# Calcular a matriz de confusão
matriz_confusao_ipm <- confusionMatrix(previsoes_classe_ipm, pred_teste_ipm$cenarios)
print(matriz_confusao_ipm)

# Fazer previsões no conjunto de teste (probabilidades)
probs_previsoes_ipm <- predict(modelo_brulee_ipm, new_data = pred_teste_ipm, type = "prob")

# Calcular AUC para cada classe usando a abordagem one-vs-all
auc_bnn_ipm <- sapply(levels(pred_teste_ipm$cenarios), function(class) {
  # Criar uma variável binária: 1 se for a classe atual, 0 caso contrário
  y_binario <- ifelse(pred_teste_ipm$cenarios == class, 1, 0)
  roc_obj <- roc(y_binario, probs_previsoes_ipm[[paste0(".pred_", class)]])
  auc(roc_obj)
})

# Exibir AUC para cada classe
print(auc_bnn_ipm)
cat("AUC média:", round(mean(auc_bnn_ipm), 6), "\n")


acc_bnn_ipm <- mean(as.numeric(acc_bnn_ipm))
auc_bnn_ipm <- mean(as.numeric(auc_bnn_ipm))
```





## (tpb) todo do processo binomial

### treino e teste

```{r}
# Se necessário, balancear os dados de treino binário
#if (min(table(df_logit_tp$atrasou)) / sum(table(df_logit_tp$atrasou)) < 0.1) {
#  cat("A variável resposta está desbalanceada. Realizando balanceamento...\n")
#  balanceamento <- upSample(x = df_logit_tp[, -which(names(df_logit_tp) == 'atrasou')], y = df_logit_tp$atrasou)
#  df_logit_tp_balanceado <- cbind(balanceamento, atrasou = balanceamento$Class)
#  df_logit_tp_balanceado$Class <- NULL
#  df_logit_tp <- df_logit_tp_balanceado
#} else {
#  cat("Não precisa balancear!")
#}

set.seed(123)
# preditores
X_tpb <- setdiff(names(df_logit_tp), c('atrasou'))

# Função para verificar se todas as variáveis categóricas têm pelo menos dois níveis
validar_categoricas <- function(treino, teste, variaveis_categoricas) {
  treino_valido <- all(sapply(treino[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
  teste_valido  <- all(sapply(teste[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
  
  return(treino_valido && teste_valido)
  
}

# Lista de variáveis categóricas
variaveis_categoricas <- names(df_logit_tp)[sapply(df_logit_tp, is.factor)]

# Loop para garantir que todas as variáveis categóricas no treino e tenham pelo menos dois níveis
repeat {
  # Divisão inicial
  indice_tpb <- createDataPartition(df_logit_tp$atrasou, p = 0.7, list = FALSE)
  treino_tpb <- df_logit_tp[indice_tpb, ]
  teste_tpb  <- df_logit_tp[-indice_tpb, ]
  
  # Verificar se as variáveis categóricas no treino têm pelo menos dois níveis
  if (validar_categoricas(treino_tpb, teste_tpb, variaveis_categoricas)) {
    cat("Divisão bem-sucedida. Todas as variáveis categóricas têm pelo menos dois níveis.\n")
    break
  } else {
    cat("Repetindo a divisão devido a variáveis categóricas com apenas um nível...\n")
  }
}

```


### modelo BNN

```{r}
# Função para normalização Min-Max
z_score_normalize <- function(data) {
  as.data.frame(lapply(data, function(x) {
    (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
  }))
}

min_max_normalize <- function(data) {
  as.data.frame(lapply(data, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))))
}

# Normalizar os dados de treino
pred_treino_tpb <- treino_tpb %>%
  mutate(across(all_of(variaveis_categoricas), ~ as.numeric(as.factor(.)))) %>%
  #select(-atrasou) %>%
  z_score_normalize()

# Adicionar a variável resposta ao conjunto de treino normalizado
pred_treino_tpb$atrasou <- treino_tpb$atrasou

# Normalizar os dados de teste
pred_teste_tpb <- teste_tpb %>%
  mutate(across(all_of(variaveis_categoricas), ~ as.numeric(as.factor(.)))) %>%
  #select(-atrasou) %>%
  z_score_normalize()

# Adicionar a variável resposta ao conjunto de teste normalizado
pred_teste_tpb$atrasou <- teste_tpb$atrasou

# Treinar o modelo com brulee usando a interface de fórmula
modelo_brulee_tpb <- brulee_mlp(
  atrasou ~ .,          # Fórmula especificando a variável resposta
  data = pred_treino_tpb,
  hidden_units = 50,
  epochs = 200,
  learn_rate = 0.001,
  verbose = TRUE
)

# Fazer previsões no conjunto de teste (classes)
#previsoes <- predict(modelo_brulee_tpb, new_data = pred_teste_tpb)

# Fazer previsões no conjunto de teste (probabilidades)
probs_previsoes_tpb <- predict(modelo_brulee_tpb, new_data = pred_teste_tpb, type = "prob")

# Extrair a probabilidade da classe positiva (assumindo que "1" é a classe positiva)
probs_classe_tpb <- probs_previsoes_tpb$.pred_1

# Converter pred_teste_tpb$atrasou para numérico
pred_teste_tpb$atrasou <- as.numeric(as.character(pred_teste_tpb$atrasou))

# Calcular a AUC
roc_obj_tpb <- roc(pred_teste_tpb$atrasou, probs_classe_tpb)
auc_bnn_tpb <- auc(roc_obj_tpb)
cat("AUC:", round(auc_bnn_tpb, 4), "\n")

# Definir o limite para a probabilidade (pode ser ajustado)
limite <- 0.5

# Criar vetor de previsões de classe
previsoes_classe_tpb <- ifelse(probs_classe_tpb > limite, 1, 0)
previsoes_classe_tpb <- factor(previsoes_classe_tpb, levels = c(0, 1))

# Converter a variável resposta para fator
pred_teste_tpb$atrasou <- factor(pred_teste_tpb$atrasou, levels = c(0, 1))

# Calcular a acurácia
acc_bnn_tpb <- mean(previsoes_classe_tpb == pred_teste_tpb$atrasou)
cat("Acurácia:", round(acc_bnn_tpb, 6), "\n")

# Calcular a matriz de confusão
matriz_confusao_tpb <- confusionMatrix(previsoes_classe_tpb, pred_teste_tpb$atrasou)
print(matriz_confusao_tpb)


# Fazer previsões no conjunto de teste (probabilidades)
#probs_previsoes <- predict(modelo_brulee_tpb, new_data = pred_teste_tpb, type = "prob")

# Extrair a probabilidade da classe positiva (assumindo que "1" é a classe positiva)
#probs_classe_positiva <- probs_previsoes$.pred_1

# Converter a variável resposta para numérico (caso não esteja)
y_teste_tpb <- as.numeric(as.character(pred_teste_tpb$atrasou))

# Calcular a curva ROC
roc_obj_tpb <- roc(y_teste_tpb, probs_classe_tpb)

# Calcular a AUC
auc_bnn_tpb <- auc(roc_obj_tpb)
cat("AUC:", round(auc_bnn_tpb, 6), "\n")


acc_bnn_tpb <- mean(as.numeric(acc_bnn_tpb))
auc_bnn_tpb <- mean(as.numeric(auc_bnn_tpb))
```




## (tpm) todo do processo multinomial



### treino e teste

```{r}
# Se necessário, balancear os dados de treino binário
#if (min(table(df_mnomial_tp$cenarios)) / sum(table(df_mnomial_tp$cenarios)) < 0.1) {
#  cat("A variável resposta está desbalanceada. Realizando balanceamento...\n")
#  balanceamento <- upSample(x = df_mnomial_tp[, -which(names(df_mnomial_tp) == 'cenarios')], y = df_mnomial_tp$cenarios)
#  df_mnomial_tp_balanceado <- cbind(balanceamento, cenarios = balanceamento$Class)
#  df_mnomial_tp_balanceado$Class <- NULL
#  df_mnomial_tp <- df_mnomial_tp_balanceado
#} else {
#  cat("Não precisa balancear!")
#}

set.seed(123)
# preditores
X_tpm <- setdiff(names(df_mnomial_tp), c('cenarios'))

# Função para verificar se todas as variáveis categóricas têm pelo menos dois níveis
validar_categoricas <- function(treino, variaveis_categoricas) {
  all(sapply(treino[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
}

# Lista de variáveis categóricas
validar_categoricas <- function(treino, teste, variaveis_categoricas) {
  treino_valido <- all(sapply(treino[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
  teste_valido  <- all(sapply(teste[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
  
  return(treino_valido && teste_valido)
  
}

# Lista de variáveis categóricas
variaveis_categoricas <- names(df_mnomial_tp)[sapply(df_mnomial_tp, is.factor)]

# Loop para garantir que todas as variáveis categóricas no treino e tenham pelo menos dois níveis
repeat {
  # Divisão inicial
  indice_tpm <- createDataPartition(df_mnomial_tp$cenarios, p = 0.7, list = FALSE)
  treino_tpm <- df_mnomial_tp[indice_tpm, ]
  teste_tpm  <- df_mnomial_tp[-indice_tpm, ]
  
  # Verificar se as variáveis categóricas no treino têm pelo menos dois níveis
  if (validar_categoricas(treino_tpm, teste_tpm, variaveis_categoricas)) {
    cat("Divisão bem-sucedida. Todas as variáveis categóricas têm pelo menos dois níveis.\n")
    break
  } else {
    cat("Repetindo a divisão devido a variáveis categóricas com apenas um nível...\n")
  }
}

```

### modelo BNN

```{r}
# Função para normalização Min-Max
z_score_normalize <- function(data) {
  as.data.frame(lapply(data, function(x) {
    (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
  }))
}

min_max_normalize <- function(data) {
  as.data.frame(lapply(data, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))))
}

# Normalizar os dados de treino
pred_treino_tpm <- treino_tpm %>%
  mutate(across(all_of(variaveis_categoricas), ~ as.numeric(as.factor(.)))) %>%
  #select(-cenarios) %>%
  z_score_normalize()

# Adicionar a variável resposta ao conjunto de treino normalizado
pred_treino_tpm$cenarios <- treino_tpm$cenarios

# Normalizar os dados de teste
pred_teste_tpm <- teste_tpm %>%
  mutate(across(all_of(variaveis_categoricas), ~ as.numeric(as.factor(.)))) %>%
  #select(-cenarios) %>%
  z_score_normalize()

# Adicionar a variável resposta ao conjunto de teste normalizado
pred_teste_tpm$cenarios <- teste_tpm$cenarios

# Treinar o modelo com brulee usando a interface de fórmula
modelo_brulee_tpm <- brulee_mlp(
  cenarios ~ .,          # Fórmula especificando a variável resposta
  data = pred_treino_tpm,
  hidden_units = 50,
  epochs = 200,
  learn_rate = 0.001,
  verbose = TRUE
)

# Fazer previsões no conjunto de teste (classes)
previsoes_classe_tpm <- predict(modelo_brulee_tpm, new_data = pred_teste_tpm)

# Converter para fator com os níveis corretos
previsoes_classe_tpm <- factor(previsoes_classe_tpm$.pred_class, levels = levels(pred_teste_tpm$cenarios))

# Calcular a acurácia
acc_bnn_tpm <- mean(previsoes_classe_tpm == pred_teste_tpm$cenarios)
cat("Acurácia:", round(acc_bnn_tpm, 6), "\n")

# Calcular a matriz de confusão
matriz_confusao_tpm <- confusionMatrix(previsoes_classe_tpm, pred_teste_tpm$cenarios)
print(matriz_confusao_tpm)

# Fazer previsões no conjunto de teste (probabilidades)
probs_previsoes_tpm <- predict(modelo_brulee_tpm, new_data = pred_teste_tpm, type = "prob")

# Calcular AUC para cada classe usando a abordagem one-vs-all
auc_bnn_tpm <- sapply(levels(pred_teste_tpm$cenarios), function(class) {
  # Criar uma variável binária: 1 se for a classe atual, 0 caso contrário
  y_binario <- ifelse(pred_teste_tpm$cenarios == class, 1, 0)
  roc_obj <- roc(y_binario, probs_previsoes_tpm[[paste0(".pred_", class)]])
  auc(roc_obj)
})

# Exibir AUC para cada classe
print(auc_bnn_tpm)
cat("AUC média:", round(mean(auc_bnn_tpm), 6), "\n")


acc_bnn_tpm <- mean(as.numeric(acc_bnn_tpm))
auc_bnn_tpm <- mean(as.numeric(auc_bnn_tpm))
```


# resultados

```{r}

resultados.f <- data.frame(
  Modelo = c("BNN binomial", "BNN multinomial"),
  Acc.ip = c(acc_bnn_ipb, acc_bnn_ipm),
  #BIC.ip = c(bic_ipb, bic_ipm,0),
  AUC.ip = c(auc_bnn_ipb, auc_bnn_ipm),
  
  Acc.tp  = c(acc_bnn_tpb, acc_bnn_tpm),
  #BIC.tp = c(bic_tpb, bic_tpm,0),
  AUC.tp = c(auc_bnn_tpb, auc_bnn_tpm)
  )

print(resultados.f)

load("resultados03.RData")

resultados.g <- rbind(resultados.e, resultados.f)

print(resultados.g)

save(resultados.e, file ="resultados03.RData")
```
