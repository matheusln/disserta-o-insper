---
title: "4a. logit e multinomial"
author: "Matheus Lazzari Nicola"
format: 
  html:
    math: mathjax
    code-fold: true
    code-summary: "mostre-me o código"
    embed-resources: true
    df-print: paged 
    toc: true
    toc-depth: 2
    toc-location: left
    toc-title: sumário executivo
    grid:
      sidebar-width: 200px
      body-width: 900px  
      margin-width: 200px
      gutter-width: 1.5em
editor_options: 
  chunk_output_type: inline
---

<style>
  p {
    text-align: justify;
  }
</style>

# pacotes

```{r}
#| warning: false
#| echo: false

pkgs<-c("tidyverse", "conflicted", "patchwork", "pROC",
        "caret",    # Para dividir os dados e avaliar os modelos
        "rstanarm", # para logit binomial bayesiano
        "nnet",     # Para regressão multinomial e rede neural
        "rstan",    # para logit multinomia baysiano
        "pROC"      # Para curvas ROC
       
        )

new.packages <- pkgs[!(pkgs %in% installed.packages()[,"Package"])]

if(length(new.packages)) install.packages(new.packages)

invisible(lapply(pkgs, library, character.only = TRUE))
rm(pkgs, new.packages)

conflict_prefer("filter", "dplyr")
conflict_prefer("lag", "dplyr")
conflicts_prefer(neuralnet::compute)

```

# base de dados

```{r}
load("df processo transporte.RData")
```

### validações

```{r}
# Base binária
#dados_logit$atrasou <- as.factor(dados_logit$atrasou)
#levels(dados_logit$atrasou)

# Base multinomial
#dados_mnomial$cenarios <- as.factor(dados_mnomial$cenarios)
#levels(dados_mnomial$cenarios)

# Verificar valores ausentes na base binária
#sum(is.na(dados_logit))

# Verificar valores ausentes na base multinomial
#sum(is.na(dados_mnomial))

# Verificar o balanceamento da variável resposta binária
#table(dados_logit$atrasou)
```






# processo de transporte

## (ipb) inicio do processo binomial

### treino e teste

```{r}
# Se necessário, balancear os dados de treino binário
#if (min(table(df_logit_ip$atrasou)) / sum(table(df_logit_ip$atrasou)) < 0.1) {
#  cat("A variável resposta está desbalanceada. Realizando balanceamento...\n")
#  balanceamento <- upSample(x = df_logit_ip[, -which(names(df_logit_ip) == 'atrasou')], y = df_logit_ip$atrasou)
#  df_logit_ip_balanceado <- cbind(balanceamento, atrasou = balanceamento$Class)
#  df_logit_ip_balanceado$Class <- NULL
#  df_logit_ip <- df_logit_ip_balanceado
#} else {
#  cat("Não precisa balancear!")
#}

set.seed(123)
# preditores
X_ipb <- setdiff(names(df_logit_ip), c('atrasou'))

# Função para verificar se todas as variáveis categóricas têm pelo menos dois níveis
validar_categoricas <- function(treino, teste, variaveis_categoricas) {
  treino_valido <- all(sapply(treino[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
  teste_valido  <- all(sapply(teste[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
  
  return(treino_valido && teste_valido)
  
}

# Lista de variáveis categóricas
variaveis_categoricas <- names(df_logit_ip)[sapply(df_logit_ip, is.factor)]

# Loop para garantir que todas as variáveis categóricas no treino e tenham pelo menos dois níveis
repeat {
  # Divisão inicial
  indice_ipb <- createDataPartition(df_logit_ip$atrasou, p = 0.7, list = FALSE)
  treino_ipb <- df_logit_ip[indice_ipb, ]
  teste_ipb  <- df_logit_ip[-indice_ipb, ]
  
  # Verificar se as variáveis categóricas no treino têm pelo menos dois níveis
  if (validar_categoricas(treino_ipb, teste_ipb, variaveis_categoricas)) {
    cat("Divisão bem-sucedida. Todas as variáveis categóricas têm pelo menos dois níveis.\n")
    break
  } else {
    cat("Repetindo a divisão devido a variáveis categóricas com apenas um nível...\n")
  }
}


```


### modelo logit

```{r}
# 1. Regressão Logística Binomial
formula_ipb <- as.formula(paste("atrasou ~", paste(X_ipb, collapse = " + ")))
modelo_ipb  <- glm(formula_ipb, data = treino_ipb, family = binomial)

# Avaliar Regressão Logística Binomial
probPred_ipb <- predict(modelo_ipb, teste_ipb, type = "response")
classPred_ipb <- ifelse(probPred_ipb > 0.5, "1", "0")
confMat_ipb <- confusionMatrix(as.factor(classPred_ipb), as.factor(teste_ipb$atrasou), dnn = c("Prediction", "Reference"))
print(confMat_ipb)


```


### modelo logit bayesiano

```{r}
# Suponha que treino_ipb e teste_ipb já existam
# Ajustando um modelo logístico bayesiano com priors default
modelo_ipb_bayes <- stan_glm(
  formula_ipb,
  data = treino_ipb,
  family = binomial(link = "logit"),
  prior = normal(0, 0.5),
  seed = 123,
  chains = 2,      # apenas 1 cadeia
  iter = 1000,      # menos iterações totais 
  warmup = 25,      # warmup mais curto
  cores = 2,
  control = list(adapt_delta = 0.99, stepsize = 0.01)
)

# Fazer previsões no conjunto de teste
prob_pred <- posterior_predict(modelo_ipb_bayes, newdata = teste_ipb, draws = 1000)

# Calcular a média das previsões para obter probabilidades médias
prob_mean <- colMeans(prob_pred)

# Definir um limiar para classificar as previsões em 0 ou 1 (padrão é 0.5)
y_pred <- ifelse(prob_mean > 0.5, 1, 0)

# Obter os valores reais no conjunto de teste
y_teste <- teste_ipb$atrasou  # Ajuste conforme o nome da variável de resposta

# Converter para fatores
y_pred_factor <- as.factor(y_pred)
y_teste_factor <- as.factor(y_teste)

# Calcular a matriz de confusão
confMat_ipb <- confusionMatrix(y_pred_factor, y_teste_factor, dnn = c("Prediction", "Reference"))

# Exibir a matriz de confusão
print(confMat_ipb)
```





## (ipm) inicio do processo multinomial


### treino e teste

```{r}
# Se necessário, balancear os dados de treino binário
#if (min(table(df_mnomial_ip$cenarios)) / sum(table(df_mnomial_ip$cenarios)) < 0.1) {
#  cat("A variável resposta está desbalanceada. Realizando balanceamento...\n")
#  balanceamento <- upSample(x = df_mnomial_ip[, -which(names(df_mnomial_ip) == 'cenarios')], y = df_mnomial_ip$cenarios)
#  df_mnomial_ip_balanceado <- cbind(balanceamento, cenarios = balanceamento$Class)
#  df_mnomial_ip_balanceado$Class <- NULL
#  df_mnomial_ip <- df_mnomial_ip_balanceado
#} else {
#  cat("Não precisa balancear!")
#}

set.seed(123)
# preditores
X_ipm <- setdiff(names(df_mnomial_ip), c('cenarios'))

# Função para verificar se todas as variáveis categóricas têm pelo menos dois níveis
validar_categoricas <- function(treino, teste, variaveis_categoricas) {
  treino_valido <- all(sapply(treino[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
  teste_valido  <- all(sapply(teste[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
  
  return(treino_valido && teste_valido)
  
}

# Lista de variáveis categóricas
variaveis_categoricas <- names(df_mnomial_ip)[sapply(df_mnomial_ip, is.factor)]

# Loop para garantir que todas as variáveis categóricas no treino e tenham pelo menos dois níveis
repeat {
  # Divisão inicial
  indice_ipm <- createDataPartition(df_mnomial_ip$cenarios, p = 0.7, list = FALSE)
  treino_ipm <- df_mnomial_ip[indice_ipm, ]
  teste_ipm  <- df_mnomial_ip[-indice_ipm, ]
  
  # Verificar se as variáveis categóricas no treino têm pelo menos dois níveis
  if (validar_categoricas(treino_ipm, teste_ipm, variaveis_categoricas)) {
    cat("Divisão bem-sucedida. Todas as variáveis categóricas têm pelo menos dois níveis.\n")
    break
  } else {
    cat("Repetindo a divisão devido a variáveis categóricas com apenas um nível...\n")
  }
}


```


### modelo multinomial

```{r}
# 1. Regressão Logística Binomial
formula_ipm <- as.formula(paste("cenarios ~", paste(X_ipm, collapse = " + ")))
modelo_ipm  <- multinom(formula_ipm, data = treino_ipm)

# Avaliar Regressão Logística Binomial
probPred_ipm <- predict(modelo_ipm, teste_ipm)
confMat_ipm <- confusionMatrix(as.factor(probPred_ipm), as.factor(teste_ipm$cenarios), dnn = c("Prediction", "Reference"))
print(confMat_ipm)





```


### modelo mnomial bayesiano

```{r}

# 'cenarios' deve ser uma variável numérica com valores inteiros
treino_ipm$cenarios <- as.numeric(as.factor(treino_ipm$cenarios))
teste_ipm$cenarios <- as.numeric(as.factor(teste_ipm$cenarios))

# Preditores
X_treino <- as.matrix(sapply(treino_ipm[, X_ipm], as.numeric))
y_treino <- treino_ipm$cenarios

# Dimensões necessárias para o Stan
N <- nrow(X_treino)                   # Número de observações
K <- length(unique(y_treino))         # Número de categorias
J <- ncol(X_treino)                   # Número de preditores

# Lista de dados para o Stan
stan_data <- list(N = N, K = K, J = J, x = X_treino, y = y_treino)

# Código Stan para o Modelo Multinomial Bayesiano

stan_code <- "
data {
  int<lower=1> N;              // Número de observações
  int<lower=1> K;              // Número de categorias
  int<lower=1> J;              // Número de preditores
  matrix[N, J] x;              // Matriz de preditores
  int<lower=1, upper=K> y[N];  // Variável resposta categórica
}

parameters {
  matrix[J, K - 1] beta;       // Coeficientes (K-1 porque uma categoria é a base)
}

transformed parameters {
  matrix[N, K] log_p;
  
  for (n in 1:N) {
    log_p[n, 1] = 0; // Categoria base (log-odds = 0)
    for (k in 2:K) {
      log_p[n, k] = dot_product(x[n], beta[, k - 1]);
    }
  }
}

model {
  // Priors para os coeficientes
  for (k in 1:(K - 1)) {
    beta[, k] ~ normal(0, 5);
  }

  // Likelihood
  for (n in 1:N) {
    y[n] ~ categorical_logit(to_vector(log_p[n]));
  }
}
"

conflicts_prefer(rstanarm::compare_models)
conflicts_prefer(tidyr::expand)
conflicts_prefer(rstan::extract)
conflicts_prefer(purrr::lift)
conflicts_prefer(rstan::loo)
conflicts_prefer(tidyr::pack)
conflicts_prefer(caret::R2)
conflicts_prefer(dplyr::slice)
conflicts_prefer(tidyr::unpack)

# Compilar o modelo
modelo_multinomial <- stan_model(model_code = stan_code)

# Executar o modelo
fit <- sampling(modelo_multinomial, data = stan_data, chains = 2, iter = 500, warmup = 25, seed = 123, cores = 4)

# Resumo dos resultados
print(fit, pars = c("beta"), probs = c(0.025, 0.5, 0.975))


# Extrair os coeficientes beta ajustados
beta_samples <- extract(fit)$beta
beta_mean <- apply(beta_samples, c(1, 2), mean)

# Dados de teste
X_teste <- as.matrix(sapply(teste_ipm[, X_ipm], as.numeric))
y_teste <- teste_ipm$cenarios

# Calcular log-odds e probabilidades
log_p_teste <- matrix(0, nrow = nrow(X_teste), ncol = K)
for (n in 1:nrow(X_teste)) {
  for (k in 2:K) {
    log_p_teste[n, k] <- sum(X_teste[n, ] * beta_mean[, k - 1])
  }
}

p_teste <- exp(log_p_teste)
p_teste <- p_teste / rowSums(p_teste)

# Previsões
y_pred <- max.col(p_teste)

# Acurácia
acc_mnb_ipm <- mean(y_pred == y_teste)
print(paste("Acurácia:", round(acc_mnb_ipm, 6)))



pred_df <- as.data.frame(p_teste)
colnames(pred_df) <- paste0("Class_", 1:K)

auc_list <- list()
for (i in 1:K) {
  auc_list[[i]] <- roc(as.numeric(y_teste == i), pred_df[[i]])
  print(paste("AUC para a classe", i, ":", round(auc_list[[i]]$auc, 6)))
}
auc_mnb_ipm <- auc_list[[i]]$auc



# Já temos as previsões em y_pred e os valores reais em y_teste
# Converter para fator para usar com a função confusionMatrix
y_pred_factor <- as.factor(y_pred)
y_teste_factor <- as.factor(y_teste)

# Calcular a matriz de confusão
confMat_tpm <- confusionMatrix(y_pred_factor, y_teste_factor, dnn = c("Prediction", "Reference"))

# Exibir a matriz de confusão
print(confMat_tpm)
```




## (tpb) todo do processo binomial

### treino e teste

```{r}
# Se necessário, balancear os dados de treino binário
#if (min(table(df_logit_tp$atrasou)) / sum(table(df_logit_tp$atrasou)) < 0.1) {
#  cat("A variável resposta está desbalanceada. Realizando balanceamento...\n")
#  balanceamento <- upSample(x = df_logit_tp[, -which(names(df_logit_tp) == 'atrasou')], y = df_logit_tp$atrasou)
#  df_logit_tp_balanceado <- cbind(balanceamento, atrasou = balanceamento$Class)
#  df_logit_tp_balanceado$Class <- NULL
#  df_logit_tp <- df_logit_tp_balanceado
#} else {
#  cat("Não precisa balancear!")
#}

set.seed(123)
# preditores
X_tpb <- setdiff(names(df_logit_tp), c('atrasou'))

# Função para verificar se todas as variáveis categóricas têm pelo menos dois níveis
validar_categoricas <- function(treino, teste, variaveis_categoricas) {
  treino_valido <- all(sapply(treino[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
  teste_valido  <- all(sapply(teste[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
  
  return(treino_valido && teste_valido)
  
}

# Lista de variáveis categóricas
variaveis_categoricas <- names(df_logit_tp)[sapply(df_logit_tp, is.factor)]

# Loop para garantir que todas as variáveis categóricas no treino e tenham pelo menos dois níveis
repeat {
  # Divisão inicial
  indice_tpb <- createDataPartition(df_logit_tp$atrasou, p = 0.7, list = FALSE)
  treino_tpb <- df_logit_tp[indice_tpb, ]
  teste_tpb  <- df_logit_tp[-indice_tpb, ]
  
  # Verificar se as variáveis categóricas no treino têm pelo menos dois níveis
  if (validar_categoricas(treino_tpb, teste_tpb, variaveis_categoricas)) {
    cat("Divisão bem-sucedida. Todas as variáveis categóricas têm pelo menos dois níveis.\n")
    break
  } else {
    cat("Repetindo a divisão devido a variáveis categóricas com apenas um nível...\n")
  }
}


```


### modelo logit

```{r}
# 1. Regressão Logística Binomial
formula_tpb <- as.formula(paste("atrasou ~", paste(X_tpb, collapse = " + ")))
modelo_tpb  <- glm(formula_tpb, data = treino_tpb, family = binomial)

# Avaliar Regressão Logística Binomial
probPred_tpb <- predict(modelo_tpb, teste_tpb, type = "response")
classPred_tpb <- ifelse(probPred_tpb > 0.5, "1", "0")
confMat_tpb <- confusionMatrix(as.factor(classPred_tpb), as.factor(teste_tpb$atrasou), dnn = c("Prediction", "Reference"))
print(confMat_tpb)


```

### modelo logit bayesiano

```{r}
# Suponha que treino_ipb e teste_ipb já existam
# Ajustando um modelo logístico bayesiano com priors default
modelo_tpb_bayes <- stan_glm(
  formula_tpb,
  data = treino_tpb,
  family = binomial(link = "logit"),
  prior = normal(0, 0.5),
  seed = 123,
  chains = 2,      # apenas 1 cadeia
  iter = 1000,      # menos iterações totais 
  warmup = 50,      # warmup mais curto
  cores = 2,
  control = list(adapt_delta = 0.99, stepsize = 0.01)
)


# Fazer previsões no conjunto de teste
prob_pred <- posterior_predict(modelo_ipb_bayes, newdata = teste_ipb, draws = 1000)

# Calcular a média das previsões para obter probabilidades médias
prob_mean <- colMeans(prob_pred)

# Definir um limiar para classificar as previsões em 0 ou 1 (padrão é 0.5)
y_pred <- ifelse(prob_mean > 0.5, 1, 0)

# Obter os valores reais no conjunto de teste
y_teste <- teste_ipb$atrasou  # Ajuste conforme o nome da variável de resposta

# Converter para fatores
y_pred_factor <- as.factor(y_pred)
y_teste_factor <- as.factor(y_teste)

# Calcular a matriz de confusão
confMat_ipb <- confusionMatrix(y_pred_factor, y_teste_factor, dnn = c("Prediction", "Reference"))

# Exibir a matriz de confusão
print(confMat_ipb)
```



## (tpm) todo do processo multinomial



### treino e teste

```{r}
# Se necessário, balancear os dados de treino binário
#if (min(table(df_mnomial_tp$cenarios)) / sum(table(df_mnomial_tp$cenarios)) < 0.1) {
#  cat("A variável resposta está desbalanceada. Realizando balanceamento...\n")
#  balanceamento <- upSample(x = df_mnomial_tp[, -which(names(df_mnomial_tp) == 'cenarios')], y = df_mnomial_tp$cenarios)
#  df_mnomial_tp_balanceado <- cbind(balanceamento, cenarios = balanceamento$Class)
#  df_mnomial_tp_balanceado$Class <- NULL
#  df_mnomial_tp <- df_mnomial_tp_balanceado
#} else {
#  cat("Não precisa balancear!")
#}

set.seed(123)
# preditores
X_tpm <- setdiff(names(df_mnomial_tp), c('cenarios'))

# Função para verificar se todas as variáveis categóricas têm pelo menos dois níveis
validar_categoricas <- function(treino, teste, variaveis_categoricas) {
  treino_valido <- all(sapply(treino[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
  teste_valido  <- all(sapply(teste[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
  
  return(treino_valido && teste_valido)
  
}

# Lista de variáveis categóricas
variaveis_categoricas <- names(df_mnomial_tp)[sapply(df_mnomial_tp, is.factor)]

# Loop para garantir que todas as variáveis categóricas no treino e tenham pelo menos dois níveis
repeat {
  # Divisão inicial
  indice_tpm <- createDataPartition(df_mnomial_tp$cenarios, p = 0.7, list = FALSE)
  treino_tpm <- df_mnomial_tp[indice_tpm, ]
  teste_tpm  <- df_mnomial_tp[-indice_tpm, ]
  
  # Verificar se as variáveis categóricas no treino têm pelo menos dois níveis
  if (validar_categoricas(treino_tpm, teste_tpm, variaveis_categoricas)) {
    cat("Divisão bem-sucedida. Todas as variáveis categóricas têm pelo menos dois níveis.\n")
    break
  } else {
    cat("Repetindo a divisão devido a variáveis categóricas com apenas um nível...\n")
  }
}



```

### modelo multinomial

```{r}
# 1. Regressão Logística Binomial
formula_tpm <- as.formula(paste("cenarios ~", paste(X_tpm, collapse = " + ")))
modelo_tpm  <- multinom(formula_tpm, data = treino_tpm)

# Avaliar Regressão Logística Binomial
probPred_tpm <- predict(modelo_tpm, teste_tpm)
confMat_tpm <- confusionMatrix(as.factor(probPred_tpm), as.factor(teste_tpm$cenarios), dnn = c("Prediction", "Reference"))
print(confMat_tpm)

#rm(indice_tpm, validar_categoricas, variaveis_categoricas,
#   X_tpm, formula_tpm, probPred_tpm, classPred_tpm, balanceamento, df_mnomial_tp_balanceado)



```


### modelo mnomial bayesiano

```{r}

# 'cenarios' deve ser uma variável numérica com valores inteiros
treino_tpm$cenarios <- as.numeric(as.factor(treino_tpm$cenarios))
teste_tpm$cenarios <- as.numeric(as.factor(teste_tpm$cenarios))

# Preditores
X_treino <- as.matrix(sapply(treino_tpm[, X_tpm], as.numeric))
y_treino <- treino_tpm$cenarios

# Dimensões necessárias para o Stan
N <- nrow(X_treino)                   # Número de observações
K <- length(unique(y_treino))         # Número de categorias
J <- ncol(X_treino)                   # Número de preditores

# Lista de dados para o Stan
stan_data <- list(N = N, K = K, J = J, x = X_treino, y = y_treino)

# Código Stan para o Modelo Multinomial Bayesiano

stan_code <- "
data {
  int<lower=1> N;              // Número de observações
  int<lower=1> K;              // Número de categorias
  int<lower=1> J;              // Número de preditores
  matrix[N, J] x;              // Matriz de preditores
  int<lower=1, upper=K> y[N];  // Variável resposta categórica
}

parameters {
  matrix[J, K - 1] beta;       // Coeficientes (K-1 porque uma categoria é a base)
}

transformed parameters {
  matrix[N, K] log_p;
  
  for (n in 1:N) {
    log_p[n, 1] = 0; // Categoria base (log-odds = 0)
    for (k in 2:K) {
      log_p[n, k] = dot_product(x[n], beta[, k - 1]);
    }
  }
}

model {
  // Priors para os coeficientes
  for (k in 1:(K - 1)) {
    beta[, k] ~ normal(0, 5);
  }

  // Likelihood
  for (n in 1:N) {
    y[n] ~ categorical_logit(to_vector(log_p[n]));
  }
}
"

conflicts_prefer(rstanarm::compare_models)
conflicts_prefer(tidyr::expand)
conflicts_prefer(rstan::extract)
conflicts_prefer(purrr::lift)
conflicts_prefer(rstan::loo)
conflicts_prefer(tidyr::pack)
conflicts_prefer(caret::R2)
conflicts_prefer(dplyr::slice)
conflicts_prefer(tidyr::unpack)

# Compilar o modelo
modelo_multinomial <- stan_model(model_code = stan_code)

# Executar o modelo
fit <- sampling(modelo_multinomial, data = stan_data, chains = 2, iter = 500, warmup = 25, seed = 123, cores = 4)

# Resumo dos resultados
print(fit, pars = c("beta"), probs = c(0.025, 0.5, 0.975))


# Extrair os coeficientes beta ajustados
beta_samples <- rstan::extract(fit)$beta
# Calcular a média dos coeficientes ao longo das iterações
beta_mean <- apply(beta_samples, c(2, 3), mean)  # Resultado será uma matriz 34x15

# Adicionar uma coluna de zeros para a classe de referência
beta_full <- cbind(rep(0, nrow(beta_mean)), beta_mean)  # Resultado será uma matriz 34x16


# Dados de teste
X_teste <- as.matrix(sapply(teste_tpm[, X_tpm], as.numeric))
y_teste <- teste_tpm$cenarios

# Calcular os log-odds para cada observação no teste
log_p_teste <- X_teste %*% beta_full

# Limitar os valores de log_p_teste para o intervalo [-20, 20]
log_p_teste <- pmin(pmax(log_p_teste, -20), 20)
# Converter log-odds em probabilidades
p_teste <- exp(log_p_teste)
p_teste <- p_teste / rowSums(p_teste)

# Prever a classe com a maior probabilidade
y_pred <- max.col(p_teste)

# Calcular a acurácia
acc_mnb_tpm <- mean(y_pred == y_teste)
print(paste("Acurácia:", round(acc_mnb_tpm, 6)))




# Criar um dataframe com as probabilidades preditas
pred_df <- as.data.frame(p_teste)
colnames(pred_df) <- paste0("Class_", 1:ncol(p_teste))

# Calcular a AUC para cada classe
auc_list <- list()
for (i in 1:ncol(p_teste)) {
  auc_list[[i]] <- roc(as.numeric(y_teste == i), pred_df[[i]])
  print(paste("AUC para a classe", i, ":", round(auc_list[[i]]$auc, 4)))
}

# Calcular a média das AUCs
auc_mnb_tpm <- mean(sapply(auc_list, function(x) x$auc))
print(paste("Média das AUCs:", round(auc_mnb_tpm, 4)))



auc_mnb_tpm <- auc_list[[2]]$auc



# Já temos as previsões em y_pred e os valores reais em y_teste
# Converter para fator para usar com a função confusionMatrix
y_pred_factor <- as.factor(y_pred)
y_teste_factor <- as.factor(y_teste)

# Calcular a matriz de confusão
confMat_tpm <- confusionMatrix(y_pred_factor, y_teste_factor, dnn = c("Prediction", "Reference"))

# Exibir a matriz de confusão
print(confMat_tpm)


```


# resultados

```{r}
# Calcular AUC para o modelo binomial de início do processo
roc_ipb <- roc(teste_ipb$atrasou, probPred_ipb)
auc_ipb <- auc(roc_ipb)
# Calcular AUC para o modelo binomial de todo o processo
roc_tpb <- roc(teste_tpb$atrasou, probPred_tpb)
auc_tpb <- auc(roc_tpb)
# Calcular AUC para o modelo multinomial de início do processo
probPred_ipm <- predict(modelo_ipm, teste_ipm, type = "prob")
auc_ipm <- multiclass.roc(teste_ipm$cenarios, probPred_ipm)$auc
# Calcular AUC para o modelo multinomial de todo o processo
probPred_tpm <- predict(modelo_tpm, teste_tpm, type = "prob")
auc_tpm <- multiclass.roc(teste_tpm$cenarios, probPred_tpm)$auc


post_pred <- posterior_predict(modelo_ipb_bayes, newdata = teste_ipb)
# Isso retorna uma matriz com dimensões [N_draws x N_amostras_de_teste]
# Você pode tomar a média ao longo dos draws para cada observação:
mean_preds <- colMeans(post_pred)
# Em caso de modelo binário, mean_preds seria a probabilidade média posterior de ser classe "1".
class_preds <- ifelse(mean_preds > 0.5, "1", "0")
confMat_bayes <- confusionMatrix(as.factor(class_preds), as.factor(teste_ipb$atrasou))
acc_ipb_bayes <- confMat_bayes$overall['Accuracy']
post_pred <- posterior_predict(modelo_tpb_bayes, newdata = teste_tpb)
# Isso retorna uma matriz com dimensões [N_draws x N_amostras_de_teste]
# Você pode tomar a média ao longo dos draws para cada observação:
mean_preds <- colMeans(post_pred)
# Em caso de modelo binário, mean_preds seria a probabilidade média posterior de ser classe "1".
class_preds <- ifelse(mean_preds > 0.5, "1", "0")
confMat_bayes <- confusionMatrix(as.factor(class_preds), as.factor(teste_tpb$atrasou))
acc_tpb_bayes <- confMat_bayes$overall['Accuracy']

# Para um modelo binário em brms:
post_pred_probs <- posterior_epred(modelo_ipb_bayes, newdata = teste_ipb)
# Isso gera probabilidades esperadas posterior para cada observação.
# Normalmente, será um array [N_draws x N_amostras_de_teste].
mean_prob <- colMeans(post_pred_probs)
roc_bayes <- roc(teste_ipb$atrasou, mean_prob)
auc_ipb_bayes <- auc(roc_bayes)
# Para um modelo binário em brms:
post_pred_probs <- posterior_epred(modelo_tpb_bayes, newdata = teste_tpb)
# Isso gera probabilidades esperadas posterior para cada observação.
# Normalmente, será um array [N_draws x N_amostras_de_teste].
mean_prob <- colMeans(post_pred_probs)
roc_bayes <- roc(teste_tpb$atrasou, mean_prob)
auc_tpb_bayes <- auc(roc_bayes)




resultados.a <- data.frame(
  Modelo = c("Logit", "Multinomial", "Logit Bayesiano", "Multinomial Bayesiano"),
  Acc.ip = c(confMat_ipb$overall['Accuracy'], confMat_ipm$overall['Accuracy'], acc_ipb_bayes, 0.14176),
  #BIC.ip = c(bic_ipb, bic_ipm,0),
  AUC.ip = c(auc_ipb, auc_ipm, auc_ipb_bayes, 0.50000),
  
  Acc.tp  = c(confMat_tpb$overall['Accuracy'], confMat_tpm$overall['Accuracy'], acc_tpb_bayes, 0.076177),
  #BIC.tp = c(bic_tpb, bic_tpm,0),
  AUC.tp = c(auc_tpb, auc_tpm, auc_tpb_bayes, 0.5092)
  )

print(resultados.a)

save(resultados.a, file = "resultados01.RData")


```

Explicação das Métricas
BIC: Valores menores indicam melhor ajuste do modelo com penalização para complexidade.
AUC: Mede a capacidade do modelo de distinguir entre classes. Valores próximos de 1 indicam excelente desempenho.
Accuracy: Percentual de previsões corretas.


