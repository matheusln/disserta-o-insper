---
title: "5. modelos BART"
author: "Matheus Lazzari Nicola"
format: 
  html:
    math: mathjax
    code-fold: true
    code-summary: "mostre-me o código"
    embed-resources: true
    df-print: paged 
    toc: true
    toc-depth: 2
    toc-location: left
    toc-title: sumário executivo
    grid:
      sidebar-width: 200px
      body-width: 900px  
      margin-width: 200px
      gutter-width: 1.5em
editor_options: 
  chunk_output_type: console
---

<style>
  p {
    text-align: justify;
  }
</style>

# pacotes

```{r}
#| warning: false
#| echo: false

pkgs<-c("tidyverse", "conflicted", "patchwork", "pROC",
        "caret",    # Para dividir os dados e avaliar os modelos
        # para logit binomial bayesiano
        "dbarts",     # Para o modelo BART binomial
        "Matrix",     # Para o modelo BART multinomial
        "xgboost"     # Para o modelo BART multinomial
      
        )

new.packages <- pkgs[!(pkgs %in% installed.packages()[,"Package"])]

if(length(new.packages)) install.packages(new.packages)

invisible(lapply(pkgs, library, character.only = TRUE))
rm(pkgs, new.packages)

conflict_prefer("filter", "dplyr")
conflict_prefer("lag", "dplyr")
conflicts_prefer(neuralnet::compute)

```

# base de dados

```{r}
setwd("C:/Users/mathe/OneDrive/4.0 Pós-graduação/4.4b Dissertação Mestrado Profissional/d. modelos")
load("df processo transporte.RData")
```






# processo de transporte

## (ipb) inicio do processo binomial

### treino e teste

```{r}
# Se necessário, balancear os dados de treino binário
#if (min(table(df_logit_ip$atrasou)) / sum(table(df_logit_ip$atrasou)) < 0.1) {
#  cat("A variável resposta está desbalanceada. Realizando balanceamento...\n")
#  balanceamento <- upSample(x = df_logit_ip[, -which(names(df_logit_ip) == 'atrasou')], y = df_logit_ip$atrasou)
#  df_logit_ip_balanceado <- cbind(balanceamento, atrasou = balanceamento$Class)
#  df_logit_ip_balanceado$Class <- NULL
#  df_logit_ip <- df_logit_ip_balanceado
#} else {
#  cat("Não precisa balancear!")
#}

set.seed(123)
# preditores
X_ipb <- setdiff(names(df_logit_ip), c('atrasou'))

# Função para verificar se todas as variáveis categóricas têm pelo menos dois níveis
validar_categoricas <- function(treino, teste, variaveis_categoricas) {
  treino_valido <- all(sapply(treino[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
  teste_valido  <- all(sapply(teste[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
  
  return(treino_valido && teste_valido)
  
}

# Lista de variáveis categóricas
variaveis_categoricas <- names(df_logit_ip)[sapply(df_logit_ip, is.factor)]

# Loop para garantir que todas as variáveis categóricas no treino e tenham pelo menos dois níveis
repeat {
  # Divisão inicial
  indice_ipb <- createDataPartition(df_logit_ip$atrasou, p = 0.7, list = FALSE)
  treino_ipb <- df_logit_ip[indice_ipb, ]
  teste_ipb  <- df_logit_ip[-indice_ipb, ]
  
  # Verificar se as variáveis categóricas no treino têm pelo menos dois níveis
  if (validar_categoricas(treino_ipb, teste_ipb, variaveis_categoricas)) {
    cat("Divisão bem-sucedida. Todas as variáveis categóricas têm pelo menos dois níveis.\n")
    break
  } else {
    cat("Repetindo a divisão devido a variáveis categóricas com apenas um nível...\n")
  }
}

```


### modelo BART

```{r}
# 3. BART com Variável Endógena Binomial
y_ipb <- as.numeric(as.character(treino_ipb$atrasou))

modelo_ipb <- bart(
                x.train = treino_ipb[, X_ipb],
                y.train = y_ipb,
                x.test = teste_ipb[, X_ipb],
                ntree = 2000,
                verbose = TRUE
)

# Previsões de probabilidade para a base de teste
previsoes_prob_ipb <- colMeans(modelo_ipb$yhat.test)

# Verificar se as previsões foram geradas corretamente
if (length(previsoes_prob_ipb) == 0) {
  stop("O modelo não gerou previsões.")
}

# Converter probabilidades em previsões binárias usando 0.5 como ponto de corte
previsoes_ipb <- ifelse(previsoes_prob_ipb > 0.5, 1, 0)

# Valores reais da variável resposta na base de teste
y_teste_ipb <- as.numeric(as.character(teste_ipb$atrasou))

# Calcular a acurácia
acc_bart_ipb <- sum(previsoes_ipb == y_teste_ipb) / length(y_teste_ipb)
cat("Acurácia:", round(acc_bart_ipb, 4), "\n")

# Calcular a AUC
roc_obj_ipb <- roc(y_teste_ipb, previsoes_prob_ipb)
auc_bart_ipb <- auc(roc_obj_ipb)
cat("AUC:", round(auc_bart_ipb, 4), "\n")


# Converter as previsões e valores reais para fatores
previsoes_ipb_factor <- as.factor(previsoes_ipb)
y_teste_ipb_factor <- as.factor(y_teste_ipb)

# Calcular a matriz de confusão
confMat_bart_ipb <- confusionMatrix(previsoes_ipb_factor, y_teste_ipb_factor, dnn = c("Prediction", "Reference"))

# Exibir a matriz de confusão
print(confMat_bart_ipb)

```






## (ipm) inicio do processo multinomial


### treino e teste

```{r}
# Se necessário, balancear os dados de treino binário
#if (min(table(df_mnomial_ip$cenarios)) / sum(table(df_mnomial_ip$cenarios)) < 0.1) {
#  cat("A variável resposta está desbalanceada. Realizando balanceamento...\n")
#  balanceamento <- upSample(x = df_mnomial_ip[, -which(names(df_mnomial_ip) == 'cenarios')], y = df_mnomial_ip$cenarios)
#  df_mnomial_ip_balanceado <- cbind(balanceamento, cenarios = balanceamento$Class)
#  df_mnomial_ip_balanceado$Class <- NULL
#  df_mnomial_ip <- df_mnomial_ip_balanceado
#} else {
#  cat("Não precisa balancear!")
#}

set.seed(123)
# preditores
X_ipm <- setdiff(names(df_mnomial_ip), c('cenarios'))

# Função para verificar se todas as variáveis categóricas têm pelo menos dois níveis
validar_categoricas <- function(treino, variaveis_categoricas) {
  all(sapply(treino[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
}

# Lista de variáveis categóricas
validar_categoricas <- function(treino, teste, variaveis_categoricas) {
  treino_valido <- all(sapply(treino[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
  teste_valido  <- all(sapply(teste[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
  
  return(treino_valido && teste_valido)
  
}

# Lista de variáveis categóricas
variaveis_categoricas <- names(df_mnomial_ip)[sapply(df_mnomial_ip, is.factor)]

# Loop para garantir que todas as variáveis categóricas no treino e tenham pelo menos dois níveis
repeat {
  # Divisão inicial
  indice_ipm <- createDataPartition(df_mnomial_ip$cenarios, p = 0.7, list = FALSE)
  treino_ipm <- df_mnomial_ip[indice_ipb, ]
  teste_ipm  <- df_mnomial_ip[-indice_ipb, ]
  
  # Verificar se as variáveis categóricas no treino têm pelo menos dois níveis
  if (validar_categoricas(treino_ipm, teste_ipm, variaveis_categoricas)) {
    cat("Divisão bem-sucedida. Todas as variáveis categóricas têm pelo menos dois níveis.\n")
    break
  } else {
    cat("Repetindo a divisão devido a variáveis categóricas com apenas um nível...\n")
  }
}

```


### modelo BART multinomial

```{r}
# Pré-processamento: Converter variáveis categóricas em variáveis dummy
dummies_ipm <- dummyVars(" ~ .", data = treino_ipm[, X_ipm])
x_train_ipm <- predict(dummies_ipm, newdata = treino_ipm)
x_test_ipm <- predict(dummies_ipm, newdata = teste_ipm)

# Converter para matrizes esparsas
x_train_ipm <- Matrix(x_train_ipm, sparse = TRUE)
x_test_ipm <- Matrix(x_test_ipm, sparse = TRUE)

# 2. Preparar a variável resposta como numérica (para xgboost)
y_train_ipm <- as.numeric(treino_ipm$cenarios) - 1  # Subtrair 1 para que a primeira classe seja 0

# 3. Configurar parâmetros para o modelo xgboost multinomial
num_classes_ipm <- length(levels(treino_ipm$cenarios))
params_ipm <- list(
  objective = "multi:softprob",  # Classificação multiclasse
  num_class = num_classes_ipm,      # Número de classes
  eval_metric = "merror"        # Métrica de erro de classificação
)

# 4. Treinar o modelo xgboost
xgb_model_ipm <- xgboost(
  data = x_train_ipm,
  label = y_train_ipm,
  params = params_ipm,
  nrounds = 1000,                 # Número de iterações (ajuste conforme necessário)
  verbose = 1,
  early_stopping_rounds = 10     # Parada precoce para evitar overfitting
)

# Fazer previsões no conjunto de teste
pred_prob_ipm <- predict(xgb_model_ipm, x_test_ipm)
pred_prob_matrix_ipm <- matrix(pred_prob_ipm, nrow = nrow(x_test_ipm), byrow = TRUE)

# Obter as classes previstas
pred_class_ipm <- apply(pred_prob_matrix_ipm, 1, which.max) - 1  # Índices começam em 0

# Rótulos originais das classes
class_labels_ipm <- levels(treino_ipm$cenarios)
pred_class_labels_ipm <- class_labels_ipm[pred_class_ipm + 1]  # Ajustar para os rótulos originais

# Valores reais da variável resposta no conjunto de teste
y_test_labels_ipm <- teste_ipm$cenarios

# Calcular a matriz de confusão usando caret
confMat_ipm <- confusionMatrix(as.factor(pred_class_labels_ipm), as.factor(y_test_labels_ipm), dnn = c("Prediction", "Reference"))

# Exibir a matriz de confusão
print(confMat_ipm)

# Calcular a acurácia
acc_ipm <- confMat_ipm$overall['Accuracy']
print(paste("Acurácia:", round(acc_ipm, 6)))

# Calcular a AUC Multiclasse usando One-vs-All
colnames(pred_prob_matrix_ipm) <- class_labels_ipm
y_test_numeric_ipm <- as.numeric(as.factor(y_test_labels_ipm))

# Calcular a AUC Multiclasse
multiclass_roc_ipm <- multiclass.roc(y_test_numeric_ipm, pred_prob_matrix_ipm)
auc_ipm <- multiclass_roc_ipm$auc
print(paste("AUC:", round(auc_ipm, 6)))




```





## (tpb) todo do processo binomial

### treino e teste

```{r}
# Se necessário, balancear os dados de treino binário
#if (min(table(df_logit_tp$atrasou)) / sum(table(df_logit_tp$atrasou)) < 0.1) {
#  cat("A variável resposta está desbalanceada. Realizando balanceamento...\n")
#  balanceamento <- upSample(x = df_logit_tp[, -which(names(df_logit_tp) == 'atrasou')], y = df_logit_tp$atrasou)
#  df_logit_tp_balanceado <- cbind(balanceamento, atrasou = balanceamento$Class)
#  df_logit_tp_balanceado$Class <- NULL
#  df_logit_tp <- df_logit_tp_balanceado
#} else {
#  cat("Não precisa balancear!")
#}

set.seed(123)
# preditores
X_tpb <- setdiff(names(df_logit_tp), c('atrasou'))

# Função para verificar se todas as variáveis categóricas têm pelo menos dois níveis
validar_categoricas <- function(treino, teste, variaveis_categoricas) {
  treino_valido <- all(sapply(treino[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
  teste_valido  <- all(sapply(teste[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
  
  return(treino_valido && teste_valido)
  
}

# Lista de variáveis categóricas
variaveis_categoricas <- names(df_logit_tp)[sapply(df_logit_tp, is.factor)]

# Loop para garantir que todas as variáveis categóricas no treino e tenham pelo menos dois níveis
repeat {
  # Divisão inicial
  indice_tpb <- createDataPartition(df_logit_tp$atrasou, p = 0.7, list = FALSE)
  treino_tpb <- df_logit_tp[indice_tpb, ]
  teste_tpb  <- df_logit_tp[-indice_tpb, ]
  
  # Verificar se as variáveis categóricas no treino têm pelo menos dois níveis
  if (validar_categoricas(treino_tpb, teste_tpb, variaveis_categoricas)) {
    cat("Divisão bem-sucedida. Todas as variáveis categóricas têm pelo menos dois níveis.\n")
    break
  } else {
    cat("Repetindo a divisão devido a variáveis categóricas com apenas um nível...\n")
  }
}

```


### modelo BART

```{r}
# 3. BART com Variável Endógena Binomial
y_tpb <- as.numeric(as.character(treino_tpb$atrasou))

modelo_tpb <- bart(
                x.train = treino_tpb[, X_tpb],
                y.train = y_tpb,
                x.test = teste_tpb[, X_tpb],
                ntree = 2000,
                verbose = TRUE
)

# Previsões de probabilidade para a base de teste
previsoes_prob_tpb <- colMeans(modelo_tpb$yhat.test)

# Verificar se as previsões foram geradas corretamente
if (length(previsoes_prob_tpb) == 0) {
  stop("O modelo não gerou previsões.")
}

# Converter as previsões e os valores reais para fatores
previsoes_tpb_factor <- as.factor(previsoes_tpb)
y_teste_tpb_factor <- as.factor(y_teste_tpb)

# Calcular a matriz de confusão
confMat_bart_tpb <- confusionMatrix(previsoes_tpb_factor, y_teste_tpb_factor, dnn = c("Prediction", "Reference"))

# Exibir a matriz de confusão
print(confMat_bart_tpb)

# Calcular a acurácia
acc_bart_tpb <- confMat_bart_tpb$overall['Accuracy']
cat("Acurácia:", round(acc_bart_tpb, 4), "\n")

# Calcular a AUC
roc_obj_tpb <- roc(y_teste_tpb, previsoes_prob_tpb)
auc_bart_tpb <- auc(roc_obj_tpb)
cat("AUC:", round(auc_bart_tpb, 4), "\n")
```




## (tpm) todo do processo multinomial



### treino e teste

```{r}
# Se necessário, balancear os dados de treino binário
#if (min(table(df_mnomial_tp$cenarios)) / sum(table(df_mnomial_tp$cenarios)) < 0.1) {
#  cat("A variável resposta está desbalanceada. Realizando balanceamento...\n")
#  balanceamento <- upSample(x = df_mnomial_tp[, -which(names(df_mnomial_tp) == 'cenarios')], y = df_mnomial_tp$cenarios)
#  df_mnomial_tp_balanceado <- cbind(balanceamento, cenarios = balanceamento$Class)
#  df_mnomial_tp_balanceado$Class <- NULL
#  df_mnomial_tp <- df_mnomial_tp_balanceado
#} else {
#  cat("Não precisa balancear!")
#}

set.seed(123)
# preditores
X_tpm <- setdiff(names(df_mnomial_tp), c('cenarios'))

# Função para verificar se todas as variáveis categóricas têm pelo menos dois níveis
validar_categoricas <- function(treino, variaveis_categoricas) {
  all(sapply(treino[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
}

# Lista de variáveis categóricas
validar_categoricas <- function(treino, teste, variaveis_categoricas) {
  treino_valido <- all(sapply(treino[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
  teste_valido  <- all(sapply(teste[, variaveis_categoricas, drop = FALSE], function(x) length(unique(x)) >= 2))
  
  return(treino_valido && teste_valido)
  
}

# Lista de variáveis categóricas
variaveis_categoricas <- names(df_mnomial_tp)[sapply(df_mnomial_tp, is.factor)]

# Loop para garantir que todas as variáveis categóricas no treino e tenham pelo menos dois níveis
repeat {
  # Divisão inicial
  indice_tpm <- createDataPartition(df_mnomial_tp$cenarios, p = 0.7, list = FALSE)
  treino_tpm <- df_mnomial_tp[indice_tpm, ]
  teste_tpm  <- df_mnomial_tp[-indice_tpm, ]
  
  # Verificar se as variáveis categóricas no treino têm pelo menos dois níveis
  if (validar_categoricas(treino_tpm, teste_tpm, variaveis_categoricas)) {
    cat("Divisão bem-sucedida. Todas as variáveis categóricas têm pelo menos dois níveis.\n")
    break
  } else {
    cat("Repetindo a divisão devido a variáveis categóricas com apenas um nível...\n")
  }
}

```

### modelo BART

```{r}
# Pré-processamento: Converter variáveis categóricas em variáveis dummy
dummies_tpm <- dummyVars(" ~ .", data = treino_tpm[, X_tpm])
x_train_tpm <- predict(dummies_tpm, newdata = treino_tpm)
x_test_tpm <- predict(dummies_tpm, newdata = teste_tpm)

# Converter para matrizes esparsas
x_train_tpm <- Matrix(x_train_tpm, sparse = TRUE)
x_test_tpm <- Matrix(x_test_tpm, sparse = TRUE)

# 2. Preparar a variável resposta como numérica (para xgboost)
y_train_tpm <- as.numeric(treino_tpm$cenarios) - 1  # Subtrair 1 para que a primeira classe seja 0

# 3. Configurar parâmetros para o modelo xgboost multinomial
num_classes_tpm <- length(levels(treino_tpm$cenarios))
params_tpm <- list(
  objective = "multi:softprob",  # Classificação multiclasse
  num_class = num_classes_tpm,      # Número de classes
  eval_metric = "merror"        # Métrica de erro de classificação
)

# 4. Treinar o modelo xgboost
xgb_model_tpm <- xgboost(
  data = x_train_tpm,
  label = y_train_tpm,
  params = params_tpm,
  nrounds = 10000,                 # Número de iterações (ajuste conforme necessário)
  verbose = 1,
  early_stopping_rounds = 10     # Parada precoce para evitar overfitting
)

# Fazer previsões no conjunto de teste
pred_prob_tpm <- predict(xgb_model_tpm, x_test_tpm)
pred_prob_matrix_tpm <- matrix(pred_prob_tpm, nrow = nrow(x_test_tpm), byrow = TRUE)

# Obter as classes previstas
pred_class_tpm <- apply(pred_prob_matrix_tpm, 1, which.max) - 1  # Índices começam em 0

# Rótulos originais das classes
class_labels_tpm <- levels(treino_tpm$cenarios)
pred_class_labels_tpm <- class_labels_tpm[pred_class_tpm + 1]  # Ajustar para os rótulos originais

# Valores reais da variável resposta no conjunto de teste
y_test_labels_tpm <- teste_tpm$cenarios

# Calcular a matriz de confusão usando caret
confMat_tpm <- confusionMatrix(as.factor(pred_class_labels_tpm), as.factor(y_test_labels_tpm), dnn = c("Prediction", "Reference"))

# Exibir a matriz de confusão
print(confMat_tpm)

# Calcular a acurácia
acc_tpm <- confMat_tpm$overall['Accuracy']
print(paste("Acurácia:", round(acc_tpm, 6)))

# Calcular a AUC Multiclasse usando One-vs-All
colnames(pred_prob_matrix_tpm) <- class_labels_tpm
y_test_numeric_tpm <- as.numeric(as.factor(y_test_labels_tpm))

# Calcular a AUC Multiclasse
multiclass_roc_tpm <- multiclass.roc(y_test_numeric_tpm, pred_prob_matrix_tpm)
auc_tpm <- multiclass_roc_tpm$auc
print(paste("AUC:", round(auc_tpm, 6)))




```


# resultados

```{r}

resultados.b <- data.frame(
  Modelo = c("BART binomial", "BART multinomial"),
  Acc.ip = c(acc_bart_ipb, acc_barte_ipm),
  #BIC.ip = c(bic_ipb, bic_ipm,0),
  AUC.ip = c(auc_bart_ipb, auc_bart_ipm),
  
  Acc.tp  = c(acc_bart_tpb, acc_bart_tpm),
  #BIC.tp = c(bic_tpb, bic_tpm,0),
  AUC.tp = c(auc_bart_tpb, auc_bart_tpm)
  )

print(resultados.b)


path.01 = "C:/Users/mathe/OneDrive/4.0 Pós-graduação/4.4b Dissertação Mestrado Profissional/d. modelos/resultados01.RData"
load(path.01)

resultados.c <- rbind(resultados.a, resultados.b)

print(resultados.c)

path.02 = "C:/Users/mathe/OneDrive/4.0 Pós-graduação/4.4b Dissertação Mestrado Profissional/d. modelos/resultados02.RData"
save(resultados.c, file = path.02)
```
